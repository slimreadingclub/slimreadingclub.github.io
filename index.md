# SLIM Reading Club

[SLIM Group](https://slim.gatech.edu/) organizes the reading club scheduled for Fridays at 10am. Students present a paper relevant to the SOTA research pratices in the fields of machine learning, uncertainty quantification, variational inference, and inverse problems. These presentations are usually informal and participants are encouraged to take part in the discussion and share experiences with specific domain knowledge. 

This website is maintained by the GitHub repository at [https://github.com/slimreadingclub/slimreadingclub.github.io](https://github.com/slimreadingclub/slimreadingclub.github.io). If you have any questions or suggestions of the reading club series, please open an issue to the repo. If you would like to join our reading club or present your favorite paper, please open a pull request.

Organizers:
Ziyi (Francis) Yin, ziyi.yin@gatech.edu    
Rafael Orozco, rorozco@gatech.edu    
Thomas J. Grady II, tgrady@gatech.edu    
Felix J. Herrmann, felix.herrmann@gatech.edu    

### The schedule for Spring 2022 SLIM Reading Club Schedule is:

**Friday 10am January 28 Generative Classifiers Part 1/3**		        
Paper: [Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification](https://arxiv.org/pdf/2001.06448.pdf)  
Presenter: Ziyi (Francis) Yin     
Outline:    
- What is a Generative Classifier
- Information Bottleneck     
- Cross Entropy 
- Cross Information     
 
**Friday 10am February 4 Generative Classifiers Part 2/3**	
Paper: [Training Normalizing Flows with the Information Bottleneck for Competitive Generative Classification](https://arxiv.org/pdf/2001.06448.pdf)  
Presenter: Ziyi (Francis) Yin     
Outline:    
- What is a Generative Classifier
- Information Bottleneck     
- Cross Entropy 
- Cross Information  	       

**Friday 10am February 11**  
**Cancelled**
 
**Friday 10am February 18 Generative Classifier Part 3/3 and FFJORD Part 1/2**  
Paper:  [Generative Classifiers as a Basis for Trustworthy Image Classification](https://arxiv.org/pdf/2007.15036.pdf)     
Presenter: Tuna Erdinc  
Outline:    
- Generative Classifier VS INN      
- Motivate with problem of normal classifiers      
- Technique for heatmaps of image that is used for classification      
- Train INN w/ IB      
- Detect OOD samples  

Paper: [FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models](https://arxiv.org/pdf/1810.01367.pdf)  
Presenter: Thomas J. Grady II	   
Outline:    
- Introduction and motivation  
- Connection to Neural ODEs  
- Refresher on generative models  
- FFJORD architecture  

**Friday 10am February 25 FFJORD Part 2/2**  				
Paper:  [FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models](https://arxiv.org/pdf/1810.01367.pdf)  
Presenter: Thomas J. Grady II	        
Outline:    
- Review of week prior  
- Numerical experiments  
- Drawbacks  
- Multiscale architecture  

**Friday 10am March 4 Stochastic Differential Equations Part 1/2**  	
Paper:  [SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS](https://arxiv.org/pdf/2011.13456.pdf)    
Paper:  [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)    
Presenter: Thomas J. Grady II   
Outline:    
- Introduction and review of diffusion   
- Discussion of score matching and Legevin dynamics     
- Discussion of diffusion result from Anderson (1982)     
- Start score-based generative modeling      

**Friday 10am March 11 Stochastic Differential Equations Part 2/2**  
Paper:  [SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS](https://arxiv.org/pdf/2011.13456.pdf)  
Presenter: Thomas J. Grady II    
Outline:     
- Review of week prior      
- Continue score-based generative modeling      
- Discussion of solvers and the reverse SDE      
- Conditional generation

**Friday 10am March 18 Likelihood-Free Inference Part 1/3**   
Paper: [BayesFlow LEARNING COMPLEX STOCHASTIC MODELS WITH INVERTIBLE NEURAL NETWORKS](https://arxiv.org/pdf/2003.06281.pdf)     
Presenter: Rafael Orozco   
Outline:     
- General Overview of Likelihood-Free methods      
- BayesFlow Theory      
- Summarizing Network      
- Training Objective      
- Preview of Main result      
	
**Friday 10am March 25 Likelihood-Free Inference Part 2/3**   
Paper: [BayesFlow LEARNING COMPLEX STOCHASTIC MODELS WITH INVERTIBLE NEURAL NETWORKS](https://arxiv.org/pdf/2003.06281.pdf).    
Presenter: Rafael Orozco   
Outline:      
-Recap of Theory     
-Applications and Results     

**Friday 10am April 8 Likelihood-Free Inference Part 3/3**      
Paper: [Deep General Expectation Maximization](https://proceedings.neurips.cc/paper/2021/file/606c90a06173d69682feb83037a68fec-Paper.pdf)   
Presenter: Rafael Orozco   
Outline:         	    
- Big EM training algorithm     
- Their results      
- Our idea for likelihood-free version of training      
- Preliminary results of Photoacoustic Joint Inverse problem         